{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import system modules\n",
    "import pandas as pd\n",
    "import ee\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import user modules\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "\n",
    "from modules.Collection import getCollection\n",
    "from modules.BandNames import getBandNames\n",
    "from modules.CloudAndShadowMask import getMasks\n",
    "from modules.SMA_NDFI import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize earth engine credentials\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest params\n",
    "RF_PARAMS = {\n",
    "    'numberOfTrees': 50,\n",
    "    'variablesPerSplit': 4,\n",
    "    'minLeafPopulation': 25\n",
    "}\n",
    "\n",
    "# define the feature space\n",
    "FEAT_SPACE_BANDS = [\"gv\", \"gvs\", \"soil\", \"npv\", \"shade\", \"ndfi\", \"csfi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples version\n",
    "V_SAMPLES = '5'\n",
    "\n",
    "samplesBaseName = 'projects/imazon-simex/LULC/SAMPLES/COLLECTION6/TRAINED/samples-amazon-collection-6-{}-{}'\n",
    "\n",
    "# number of samples\n",
    "N_SAMPLES = 10000\n",
    "\n",
    "# percentage of samples within the sample universe\n",
    "P_SAMPLES = {\"global\": 0.30, \"regional\": 0.70}\n",
    "\n",
    "# minimum number of samples per classe\n",
    "dfMinSamples = pd.DataFrame([\n",
    "    {'class':  3, 'min_samples': 4000},\n",
    "    {'class':  4, 'min_samples': 2000},\n",
    "    {'class': 12, 'min_samples':  500},\n",
    "    {'class': 15, 'min_samples': 2000},\n",
    "    {'class': 19, 'min_samples': 2000},\n",
    "    {'class': 33, 'min_samples': 2000},\n",
    "])\n",
    "\n",
    "dfMinSamples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat variables specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landsat short names\n",
    "SATELLITE_IDS = ['l5','l7','l8']\n",
    "\n",
    "# endemembers used to unmix data\n",
    "ENDMEMBERS = {\n",
    "    'l5': ENDMEMBERS_L5,\n",
    "    'l7': ENDMEMBERS_L7,\n",
    "    'l8': ENDMEMBERS_L8,\n",
    "}\n",
    "\n",
    "# landsat collection ids\n",
    "COLLECTION_IDS = {\n",
    "    'l5': 'LANDSAT/LT05/C01/T1_SR',\n",
    "    'l7': 'LANDSAT/LE07/C01/T1_SR',\n",
    "    'l8': 'LANDSAT/LC08/C01/T1_SR',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ancillary data\n",
    "## 1. Area per classe and landsat tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read areas table\n",
    "dfAreas = pd.read_csv('../data/areas.csv')\n",
    "dfAreas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Priority table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads priority table\n",
    "dfPriority = pd.read_csv('../data/priority.csv', decimal=',')\n",
    "\n",
    "# find which tiles will be processed\n",
    "dfPriority['process'] = (dfPriority['P0'] > 0.9) & (dfPriority['P0'] < 0.97)\n",
    "\n",
    "# takes the relevant columns\n",
    "dfPriority = dfPriority[['tile', 'process']]\n",
    "\n",
    "dfPriority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defective image list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads image list from trash\n",
    "trash = pd.read_json('../data/trash.json')\n",
    "\n",
    "trash = list(trash.image_id.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Landsat tiles collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads ladsat tiles collection\n",
    "ASSET_TILES = 'projects/mapbiomas-workspace/AUXILIAR/landsat-mask'\n",
    "\n",
    "tilesCollection = ee.ImageCollection(ASSET_TILES)\\\n",
    "    .filterMetadata('version', 'equals', '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Output collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output asset path\n",
    "ASSET_OUTPUT = 'projects/imazon-simex/LULC/TEST/classification-2'\n",
    "\n",
    "# output files version\n",
    "OUTPUT_VERSION = '2'\n",
    "\n",
    "# loads files from output collection\n",
    "outputCollection = ee.ImageCollection(ASSET_OUTPUT)#\\\n",
    "    # .filterMetadata('version', 'equals', OUTPUT_VERSION)\n",
    "\n",
    "# lists image files already saved in the collection\n",
    "outputAssetIds = outputCollection.reduceColumns(\n",
    "        ee.Reducer.toList(), ['system:index'])\\\n",
    "        .get('list')\\\n",
    "        .getInfo()\n",
    "\n",
    "# list of landsat image ids to skip\n",
    "skipList = map(\n",
    "    lambda imageid: imageid.replace('-' + OUTPUT_VERSION, ''),\n",
    "    outputAssetIds\n",
    ")\n",
    "\n",
    "skipList = list(skipList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data table\n",
    "## 1. Legend adjustment for Amazon classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = ['year', 'tile']\n",
    "\n",
    "dfAreas = dfAreas.replace({'class': {20: 19, 36:19, 39: 19, 41: 19}})\n",
    "\n",
    "# aggregate areas by class, tile and year\n",
    "dfAgg = dfAreas.groupby(['year', 'tile', 'class']).agg({'area': 'sum'}).reset_index()\n",
    "\n",
    "# calculate the total area per tile and year\n",
    "dfTotal = dfAreas.groupby(INDEX).agg({'area': 'sum'}).reset_index()\n",
    "\n",
    "# merges the dfAgg with dfTotal\n",
    "df = pd.merge(dfAgg, dfTotal, how=\"outer\", on=INDEX, suffixes=(None, '_total'))\n",
    "\n",
    "df[(df['tile'] == 226069) & (df['year'] == 2020)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate the proportion of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['proportion'] = df['area'].div(df['area_total'])\n",
    "\n",
    "df[(df['tile'] == 226069) & (df['year'] == 2020)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Number of samples based on proportions of area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the number of samples based on proportions\n",
    "df['n_samples'] = df['proportion'].mul(N_SAMPLES).round()\n",
    "\n",
    "df[(df['tile'] == 226069) & (df['year'] == 2020)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare the `min_samples` to `n_samples` and keep the highest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merges minimum samples per class to data table\n",
    "df = pd.merge(df, dfMinSamples, how=\"outer\", on=\"class\")\n",
    "\n",
    "# replace n_samples column with the highest value betwen min_samples and n_samples\n",
    "df.loc[df['min_samples'] > df['n_samples'], 'n_samples'] = df['min_samples']\n",
    "\n",
    "df[(df['tile'] == 226069) & (df['year'] == 2020)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Number of regional and global samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rg_samples'] = df['n_samples'].mul(P_SAMPLES['regional']).round()\n",
    "df['gl_samples'] = df['n_samples'].mul(P_SAMPLES['global']).round()\n",
    "\n",
    "df[(df['tile'] == 226069) & (df['year'] == 2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges minimum samples per class to data table\n",
    "df = pd.merge(df, dfPriority, how=\"outer\", on=\"tile\")\n",
    "\n",
    "df[(df['tile'] == 226069) & (df['year'] == 2020)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilitie functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(collection, seed=1):\n",
    "    \"\"\"\n",
    "    Adds a column of deterministic pseudorandom numbers to a collection.\n",
    "    The range 0 (inclusive) to 1000000000 (exclusive).\n",
    "    \"\"\"\n",
    "\n",
    "    collection = collection.randomColumn('random', seed)\\\n",
    "        .sort('random', True)\\\n",
    "        .map(\n",
    "            lambda feature: feature.set(\n",
    "                'new_id',\n",
    "                ee.Number(feature.get('random'))\n",
    "                .multiply(1000000000)\n",
    "                .round()\n",
    "            )\n",
    "    )\n",
    "\n",
    "    # list of random ids\n",
    "    randomIdList = ee.List(\n",
    "        collection.reduceColumns(ee.Reducer.toList(), ['new_id'])\n",
    "        .get('list'))\n",
    "\n",
    "    # list of sequential ids\n",
    "    sequentialIdList = ee.List.sequence(1, collection.size())\n",
    "\n",
    "    # set new ids\n",
    "    shuffled = collection.remap(randomIdList, sequentialIdList, 'new_id')\n",
    "\n",
    "    return shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyCloudAndShadowMask(collection):\n",
    "\n",
    "    # Get cloud and shadow masks\n",
    "    collectionWithMasks = getMasks(collection,\n",
    "                                   cloudFlag=True,\n",
    "                                   cloudScore=True,\n",
    "                                   cloudShadowFlag=True,\n",
    "                                   cloudShadowTdom=True,\n",
    "                                   zScoreThresh=-1,\n",
    "                                   shadowSumThresh=4000,\n",
    "                                   dilatePixels=2,\n",
    "                                   cloudHeights=ee.List.sequence(\n",
    "                                       200, 10000, 500),\n",
    "                                   cloudBand='cloudFlagMask')\n",
    "\n",
    "    # collectionWithMasks = collectionWithMasks.select(specCloudBands)\n",
    "\n",
    "    # get collection without clouds\n",
    "    collectionWithoutClouds = collectionWithMasks.map(\n",
    "        lambda image: image.mask(\n",
    "            image.select([\n",
    "                'cloudFlagMask',\n",
    "                'cloudScoreMask',\n",
    "                'cloudShadowFlagMask',\n",
    "                'cloudShadowTdomMask'\n",
    "            ]).reduce(ee.Reducer.anyNonZero()).eq(0)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return collectionWithoutClouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "SEGMENT_BANDS = [\"blue\", \"green\", \"red\", \"nir\", \"swir1\", \"swir2\"]\n",
    "\n",
    "def getSegments(image, size=16):\n",
    "\n",
    "    seeds = ee.Algorithms.Image.Segmentation.seedGrid(\n",
    "        size=size,\n",
    "        gridType='square'\n",
    "    )\n",
    "\n",
    "    snic = ee.Algorithms.Image.Segmentation.SNIC(\n",
    "        image=image,\n",
    "        size=size,\n",
    "        compactness=1,\n",
    "        connectivity=8,\n",
    "        neighborhoodSize=2*size,\n",
    "        seeds=seeds\n",
    "    )\n",
    "\n",
    "    snic = ee.Image(\n",
    "        snic.copyProperties(image)\n",
    "            .copyProperties(image, ['system:footprint'])\n",
    "            .copyProperties(image, ['system:time_start']))\n",
    "\n",
    "    return snic.select(['clusters'], ['segments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimilarMask(segments, samples):\n",
    "\n",
    "    samplesSegments = segments.sampleRegions(\n",
    "        collection=samples,\n",
    "        properties=['class'],\n",
    "        scale=30,\n",
    "        geometries=True\n",
    "    )\n",
    "\n",
    "    segmentsValues = ee.List(\n",
    "        samplesSegments\n",
    "        .reduceColumns(\n",
    "            ee.Reducer.toList().repeat(2),\n",
    "            ['class', 'segments']\n",
    "        ).get('list')\n",
    "    )\n",
    "\n",
    "    similiarMask = segments.remap(\n",
    "        segmentsValues.get(1),\n",
    "        segmentsValues.get(0), 0)\n",
    "\n",
    "    return similiarMask.rename(['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generateSamples(image, samples, classValues, classPoints, region, segmentsBands):\n",
    "\n",
    "    segments = getSegments(image.select(segmentsBands), size=16)\n",
    "\n",
    "    similarMask = getSimilarMask(segments, samples)\n",
    "\n",
    "    similarMask = similarMask.selfMask().rename(['class'])\n",
    "\n",
    "    newSamples = similarMask.addBands(image)\\\n",
    "        .stratifiedSample(\n",
    "            numPoints=sum(classPoints),\n",
    "            classBand='class',\n",
    "            region=region,\n",
    "            scale=30.0,\n",
    "            classValues=classValues,\n",
    "            classPoints=classPoints,\n",
    "            geometries=True\n",
    "    )\n",
    "\n",
    "    return newSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(image, samples, featSpace, numberOfTrees, variablesPerSplit, minLeafPopulation):\n",
    "\n",
    "    classifier = ee.Classifier.smileRandomForest(\n",
    "        numberOfTrees=numberOfTrees,\n",
    "        variablesPerSplit=variablesPerSplit,\n",
    "        minLeafPopulation=minLeafPopulation\n",
    "    ).train(samples, 'class', featSpace)\n",
    "\n",
    "    return ee.Image(image\n",
    "                    .select(featSpace)\n",
    "                    .classify(classifier)\n",
    "                    .rename(['classification'])\n",
    "                    .copyProperties(image)\n",
    "                    .copyProperties(image, ['system:footprint'])\n",
    "                    .copyProperties(image, ['system:time_start'])\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over years and landsat tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(pd.unique(df['year']))\n",
    "tiles = list(pd.unique(df[df['process'] == True]['tile']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for year in years:\n",
    "\n",
    "    samplesName = samplesBaseName.format(year, V_SAMPLES)\n",
    "\n",
    "    samples = ee.FeatureCollection(samplesName)\\\n",
    "        .filterMetadata('gv', 'not_equals', None)\n",
    "\n",
    "    for tile in tiles:\n",
    "\n",
    "        tileMask = tilesCollection.filterMetadata('tile', 'equals', int(tile))\n",
    "        tileMask = ee.Image(tileMask.first())\n",
    "        \n",
    "        geometry = tileMask.geometry()\n",
    "        centroid = geometry.centroid()\n",
    "\n",
    "        dfTileYear = df[(df['tile'] == tile) & (df['year'] == year)]\n",
    "\n",
    "        for satelliteId in SATELLITE_IDS:\n",
    "            try:\n",
    "                # returns a collection containing the specified parameters\n",
    "                collection = getCollection(COLLECTION_IDS[satelliteId],\n",
    "                                            dateStart=str(year)+'-01-01',\n",
    "                                            dateEnd=str(year)+'-12-31',\n",
    "                                            cloudCover=50,\n",
    "                                            geometry=centroid)\n",
    "                \n",
    "                # drops images in trash and skip lists\n",
    "                collection = collection\\\n",
    "                    .filter(ee.Filter.inList('system:index', skipList).Not())\\\n",
    "                    .filter(ee.Filter.inList('system:index', trash).Not())\n",
    "            \n",
    "                # returns the pattern of band names\n",
    "                bands = getBandNames(satelliteId)\n",
    "\n",
    "                # selects the images bands and rename it\n",
    "                collection = collection.select(\n",
    "                    bands['bandNames'],\n",
    "                    bands['newNames']\n",
    "                )\n",
    "\n",
    "                # remove clouds and shadows\n",
    "                collectionWithoutClouds = applyCloudAndShadowMask(collection)\n",
    "\n",
    "                # build the feature space bands\n",
    "                featureSpaceCollection = collectionWithoutClouds\\\n",
    "                    .map(lambda image:\n",
    "                        image.addBands(srcImg=getSMAFractions(image, ENDMEMBERS[satelliteId]), overwrite=True))\\\n",
    "                    .map(lambda image: \n",
    "                        image.addBands(srcImg=getNDFI(image), overwrite=True))\\\n",
    "                    .map(lambda image: \n",
    "                        image.addBands(srcImg=getCSFI(image), overwrite=True))\n",
    "                \n",
    "                # lists the image ids \n",
    "                imageIds = collection.reduceColumns(\n",
    "                    ee.Reducer.toList(), ['system:index'])\n",
    "\n",
    "                imageIds = imageIds.get('list').getInfo()\n",
    "                \n",
    "                for imageId in imageIds:\n",
    "                    \n",
    "                    # step 1: get the image\n",
    "                    image = featureSpaceCollection.filterMetadata(\n",
    "                        'system:index', 'equals', imageId)\n",
    "                    \n",
    "                    image = ee.Image(image.first())\n",
    "\n",
    "                    # step 2: select the regional samples\n",
    "                    rgSamples = samples.filterBounds(geometry)\n",
    "                    \n",
    "                    dfTileYear['rg_samples_gee'] = dfTileYear.apply(\n",
    "                        lambda serie: rgSamples\n",
    "                            .filterMetadata('class', 'equals', serie['class']),\n",
    "                        axis=1\n",
    "                    )\n",
    "\n",
    "                    rgSamples = ee.FeatureCollection(\n",
    "                        list(dfTileYear['rg_samples_gee'].values)).flatten()\n",
    "\n",
    "                    # step 3: generate more samples using pixel clusters (segments)\n",
    "                    classValues = list(map(lambda number: int(number), dfTileYear['class'].values))\n",
    "                    classPoints = list(map(lambda number: int(number), dfTileYear['rg_samples'].values))\n",
    "\n",
    "                    rgSamplesPlus = generateSamples(\n",
    "                        image=image, \n",
    "                        samples=rgSamples, \n",
    "                        classValues=classValues, \n",
    "                        classPoints=classPoints, \n",
    "                        region=geometry,\n",
    "                        segmentsBands=SEGMENT_BANDS\n",
    "                    )\n",
    "                    \n",
    "                    # step 4: select the global samples\n",
    "                    shuffledSamples = shuffle(samples, seed=1)\n",
    "\n",
    "                    dfTileYear['gl_samples_gee'] = dfTileYear.apply(\n",
    "                        lambda serie: shuffledSamples\n",
    "                            .filterMetadata('class', 'equals', serie['class'])\n",
    "                            .limit(serie['gl_samples']),\n",
    "                        axis=1\n",
    "                    )\n",
    "\n",
    "                    glSamples = ee.FeatureCollection(\n",
    "                        list(dfTileYear['gl_samples_gee'].values)).flatten()\n",
    "\n",
    "                    # step 5: merges rgSamples with glSamples\n",
    "                    trainingSamples = rgSamplesPlus.merge(glSamples)\n",
    "\n",
    "                    # step 7: image classification\n",
    "                    classification = classify(\n",
    "                        image=image,\n",
    "                        samples=trainingSamples,\n",
    "                        featSpace=FEAT_SPACE_BANDS,\n",
    "                        numberOfTrees=RF_PARAMS['numberOfTrees'], \n",
    "                        variablesPerSplit=RF_PARAMS['variablesPerSplit'], \n",
    "                        minLeafPopulation=RF_PARAMS['minLeafPopulation']\n",
    "                        )\n",
    "\n",
    "                    classification = classification.updateMask(tileMask)\n",
    "                    classification = classification.toByte()\n",
    "                    classification = classification.set('version', OUTPUT_VERSION)\n",
    "\n",
    "                    # step 6: export classification to gee asset\n",
    "                    imageName = '{}-{}'.format(imageId, OUTPUT_VERSION)\n",
    "                    \n",
    "                    assetId = '{}/{}'.format(ASSET_OUTPUT, imageName)\n",
    "                    \n",
    "                    region = geometry.getInfo()['coordinates']\n",
    "\n",
    "                    task = ee.batch.Export.image.toAsset(\n",
    "                        image=classification,\n",
    "                        description=imageName,\n",
    "                        assetId=assetId,\n",
    "                        pyramidingPolicy={\".default\": \"mode\"},\n",
    "                        region=region,\n",
    "                        scale=30,\n",
    "                        # maxPixels=1e+13\n",
    "                    )\n",
    "\n",
    "                    task.start()\n",
    "            except Exception as e:\n",
    "                print(e)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
